{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221516c5-46dc-44fb-a1f0-72eaad905556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f932bc4-22ee-452c-ad15-0e28e8559ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in os.listdir():\n",
    "  if 'json' in i:\n",
    "    with gzip.open(i, 'rb') as f_in:\n",
    "          with open(i.replace('.gz',''), 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30771cfc-a4fd-48a9-a3f8-ddd525ebfc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "receipts = pd.read_json('receipts.json',lines=True)\n",
    "brands = pd.read_json('brands.json',lines=True)\n",
    "users = pd.read_json('users.json',lines=True)\n",
    "'''\n",
    "receipts = read_json('receipts.json')\n",
    "users = read_json('users.json')\n",
    "brands = read_json('brands.json')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b9519-eacc-4ba1-af5d-1cb3ee249b88",
   "metadata": {},
   "source": [
    "Tried opening the original '.json.gz' files via python code, ran into a 'Expected object or value' error. Also tried adding comma to end of line but still got an error. Since this did not work so I used online sites to open the file - to get them to be viewable. For specificity: getting an error on line two for all files. For brands.json: \" Unexpected non-whitespace character after JSON at position 229 (line 2 column 1) \". I have added the json files I used in the data files folder. Decided to convert to csv via website due to issues. I understand that this would not be possible in an actually data pipeline but to complete this assignment, this is my current solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "651089e1-88af-447a-9d33-683f2259d808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Receipts Column names:\n",
      "Index(['_id__$oid', 'bonusPointsEarned', 'bonusPointsEarnedReason',\n",
      "       'createDate__$date', 'dateScanned__$date', 'finishedDate__$date',\n",
      "       'modifyDate__$date', 'pointsAwardedDate__$date', 'pointsEarned',\n",
      "       'purchaseDate__$date', 'purchasedItemCount',\n",
      "       'rewardsReceiptItemList__deleted', 'rewardsReceiptItemList__brandCode',\n",
      "       'rewardsReceiptItemList__competitorRewardsGroup',\n",
      "       'rewardsReceiptItemList__barcode',\n",
      "       'rewardsReceiptItemList__competitiveProduct',\n",
      "       'rewardsReceiptItemList__description',\n",
      "       'rewardsReceiptItemList__discountedItemPrice',\n",
      "       'rewardsReceiptItemList__finalPrice',\n",
      "       'rewardsReceiptItemList__itemNumber',\n",
      "       'rewardsReceiptItemList__itemPrice',\n",
      "       'rewardsReceiptItemList__metabriteCampaignId',\n",
      "       'rewardsReceiptItemList__originalReceiptItemText',\n",
      "       'rewardsReceiptItemList__needsFetchReview',\n",
      "       'rewardsReceiptItemList__originalFinalPrice',\n",
      "       'rewardsReceiptItemList__originalMetaBriteBarcode',\n",
      "       'rewardsReceiptItemList__originalMetaBriteItemPrice',\n",
      "       'rewardsReceiptItemList__originalMetaBriteDescription',\n",
      "       'rewardsReceiptItemList__needsFetchReviewReason',\n",
      "       'rewardsReceiptItemList__originalMetaBriteQuantityPurchased',\n",
      "       'rewardsReceiptItemList__partnerItemId',\n",
      "       'rewardsReceiptItemList__priceAfterCoupon',\n",
      "       'rewardsReceiptItemList__pointsEarned',\n",
      "       'rewardsReceiptItemList__pointsNotAwardedReason',\n",
      "       'rewardsReceiptItemList__pointsPayerId',\n",
      "       'rewardsReceiptItemList__preventTargetGapPoints',\n",
      "       'rewardsReceiptItemList__quantityPurchased',\n",
      "       'rewardsReceiptItemList__rewardsGroup',\n",
      "       'rewardsReceiptItemList__rewardsProductPartnerId',\n",
      "       'rewardsReceiptItemList__targetPrice',\n",
      "       'rewardsReceiptItemList__userFlaggedBarcode',\n",
      "       'rewardsReceiptItemList__userFlaggedDescription',\n",
      "       'rewardsReceiptItemList__userFlaggedNewItem',\n",
      "       'rewardsReceiptItemList__userFlaggedPrice',\n",
      "       'rewardsReceiptItemList__userFlaggedQuantity', 'rewardsReceiptStatus',\n",
      "       'totalSpent', 'userId'],\n",
      "      dtype='object')\n",
      " Brands Column names:\n",
      "Index(['_id__$oid', 'barcode', 'brandCode', 'category', 'categoryCode',\n",
      "       'cpg__$id__$oid', 'cpg__$ref', 'name', 'topBrand'],\n",
      "      dtype='object')\n",
      " Users Column names:\n",
      "Index(['_id__$oid', 'active', 'createdDate__$date', 'lastLogin__$date', 'role',\n",
      "       'signUpSource', 'state'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "receipts_df = pd.read_csv('receipts.csv')\n",
    "\n",
    "brands_df = pd.read_csv('brands.csv')\n",
    "\n",
    "users_df = pd.read_csv('users.csv')\n",
    "\n",
    "# Print column names\n",
    "print(\" Receipts Column names:\")\n",
    "print(receipts_df.columns)\n",
    "print(\" Brands Column names:\")\n",
    "print(brands_df.columns)\n",
    "print(\" Users Column names:\")\n",
    "print(users_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9f8e31c-16fd-421d-9960-6c93fb32b326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert CSV file to dataframe\n",
    "receipts_df = pd.read_csv('receipts.csv')\n",
    "\n",
    "brands_df = pd.read_csv('brands.csv')\n",
    "\n",
    "users_df = pd.read_csv('users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d780305d-9d5d-42b0-854a-cab67e0605fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total receipt rows: 2114\n",
      "Unique receipt id values: 322\n",
      "Null receipt id values: 1792\n"
     ]
    }
   ],
   "source": [
    "### Perform checks on receipts ###\n",
    "\n",
    "numeric_columns = ['bonusPointsEarned', 'pointsEarned', 'purchasedItemCount', 'totalSpent']\n",
    "for column in numeric_columns:\n",
    "    receipts_df[column] = pd.to_numeric(receipts_df[column], errors='coerce')  # Coerce = set as NaN\n",
    "\n",
    "# Check id field is unique & not null\n",
    "print(\"Total receipt rows:\", len(receipts_df['_id__$oid']))\n",
    "print(\"Unique receipt id values:\", receipts_df['_id__$oid'].nunique())\n",
    "print(\"Null receipt id values:\", receipts_df['_id__$oid'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1424171-2a96-46cb-9ad6-54dc6f2292d6",
   "metadata": {},
   "source": [
    "Possible null values due to how file was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d31b2c75-80d8-44c4-9411-17d2eb063e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with null userID: 1792\n"
     ]
    }
   ],
   "source": [
    "# Check if userID field is also not null or if there is diff b/w id and user id in data\n",
    "print(\"Total rows with null userID:\", receipts_df['userId'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da7e69-45e2-4fae-9e8a-8a5a0a114f05",
   "metadata": {},
   "source": [
    "Depending on how the nested json was flattened/normalized (since I did not do it using code im not sure how it was done) this can cause certain rows to be null when they should not be. Can also cause the table to be inflated -- would need to add code to specify which node/field to flatten. --Noticed same amount as null id values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc208b8e-78c8-4219-81d1-8e27fda4ebd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       bonusPointsEarned  pointsEarned  purchasedItemCount   totalSpent\n",
      "count         242.000000    267.000000          278.000000   298.000000\n",
      "mean          260.710744    667.020599           10.035971    46.711544\n",
      "min             5.000000      0.000000            0.000000     0.000000\n",
      "max           750.000000   9449.800000          335.000000  1177.840000\n"
     ]
    }
   ],
   "source": [
    "print(receipts_df[numeric_columns].describe().loc[['count', 'mean', 'min', 'max']])\n",
    "# Look at mean, min, and max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26a4d246-2c3c-4627-8c9f-f4a9878acc14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records where dateScanned__$date is before createDate:  0\n",
      "Number of records where modifyDate__$date is before createDate:  0\n",
      "Number of records where pointsAwardedDate__$date is before createDate:  0\n",
      "Number of records where purchaseDate__$date is before createDate:  264\n",
      "Number of records where finishedDate__$date is before createDate:  0\n",
      "\n",
      "Number of records where createDate__$date is after to finishedDate:  0\n",
      "Number of records where dateScanned__$date is after to finishedDate:  0\n",
      "Number of records where modifyDate__$date is after to finishedDate:  75\n",
      "Number of records where pointsAwardedDate__$date is after to finishedDate:  0\n",
      "Number of records where purchaseDate__$date is after to finishedDate:  3\n",
      "\n",
      "Number of records where dateScanned is before purchaseDate:  9\n"
     ]
    }
   ],
   "source": [
    "# Check order of dates is correct -- if there issue, would have to look into it further\n",
    "# finished date after any other date, scan prior to points awarded)\n",
    "date_fields = ['createDate__$date', 'dateScanned__$date', 'modifyDate__$date', 'pointsAwardedDate__$date',\n",
    "               'purchaseDate__$date', 'finishedDate__$date']\n",
    "\n",
    "for date_field in date_fields[1:]:\n",
    "    print(f\"Number of records where {date_field} is before createDate: \",\n",
    "          (receipts_df[date_field] < receipts_df['createDate__$date']).sum())\n",
    "print('')\n",
    "\n",
    "for date_field in date_fields[:-1]:\n",
    "    print(f\"Number of records where {date_field} is after to finishedDate: \",\n",
    "          (receipts_df[date_field] > receipts_df['finishedDate__$date']).sum())\n",
    "\n",
    "print('')\n",
    "print(\"Number of records where dateScanned is before purchaseDate: \",\n",
    "      (receipts_df['dateScanned__$date'] < receipts_df['purchaseDate__$date']).sum()) #might be issue with date/upload/ or data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d702b3f7-06ca-4eab-bd8d-c5b3d95f7540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total brand rows: 1167\n",
      "Unique brand _id values: 1167\n",
      "Null brand _id values: 0\n",
      "                             categoryCode\n",
      "category                                 \n",
      "Baby                                    1\n",
      "Baking                                  1\n",
      "Beauty                                  0\n",
      "Beauty & Personal Care                  0\n",
      "Beer Wine Spirits                       1\n",
      "Beverages                               1\n",
      "Bread & Bakery                          1\n",
      "Breakfast & Cereal                      0\n",
      "Candy & Sweets                          1\n",
      "Canned Goods & Soups                    0\n",
      "Cleaning & Home Improvement             1\n",
      "Condiments & Sauces                     0\n",
      "Dairy                                   0\n",
      "Dairy & Refrigerated                    1\n",
      "Deli                                    0\n",
      "Frozen                                  1\n",
      "Grocery                                 1\n",
      "Health & Wellness                       1\n",
      "Household                               0\n",
      "Magazines                               1\n",
      "Outdoor                                 1\n",
      "Personal Care                           1\n",
      "Snacks                                  0\n",
      "barcode\n",
      "511111000167    1\n",
      "511111616535    1\n",
      "511111616467    1\n",
      "511111616306    1\n",
      "511111616252    1\n",
      "               ..\n",
      "511111004790    2\n",
      "511111704140    2\n",
      "511111504139    2\n",
      "511111305125    2\n",
      "511111605058    2\n",
      "Length: 1160, dtype: int64\n",
      "brandCode\n",
      " MILANO                          1\n",
      "TEST BRANDCODE @1598711015353    1\n",
      "TEST BRANDCODE @1598711015496    1\n",
      "TEST BRANDCODE @1598711015538    1\n",
      "TEST BRANDCODE @1598711015578    1\n",
      "                                ..\n",
      "KLEENEX                          1\n",
      "KLONDIKE                         1\n",
      "KAHLUA                           1\n",
      "HUGGIES                          2\n",
      "GOODNITES                        2\n",
      "Length: 896, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Brands\n",
    "\n",
    "# Checking id field is unique & not null --same checks as before\n",
    "print(\"Total brand rows:\", len(brands_df['_id__$oid']))\n",
    "print(\"Unique brand _id values:\", brands_df['_id__$oid'].nunique())\n",
    "print(\"Null brand _id values:\", brands_df['_id__$oid'].isna().sum())\n",
    "\n",
    "# Checking one-to-one relationship\n",
    "print(brands_df[['category', 'categoryCode']].groupby('category').nunique())\n",
    "\n",
    "# Checking if barcodes and brand codes are unique\n",
    "print(brands_df[['barcode', '_id__$oid']].groupby('barcode').size().sort_values())\n",
    "print(brands_df[['brandCode', '_id__$oid']].groupby('brandCode').size().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "61351503-11b7-4a86-9b27-d43b1fa7f315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total user rows: 495\n",
      "Unique user _id values: 212\n",
      "Null user _id values: 0\n",
      "Number of duplicated user records:  283\n"
     ]
    }
   ],
   "source": [
    "# Users\n",
    "\n",
    "# Checking id field is unique & not null --same checks as before\n",
    "print(\"Total user rows:\", len(users_df['_id__$oid']))\n",
    "print(\"Unique user _id values:\", users_df['_id__$oid'].nunique())\n",
    "print(\"Null user _id values:\", users_df['_id__$oid'].isna().sum())\n",
    "print(\"Number of duplicated user records: \", users_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f49c673f-7ff8-499c-a473-b5aaf586a57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      totalSpent  purchasedItemCount\n",
      "rewardsReceiptStatus                                \n",
      "FINISHED               48.077269              2664.0\n",
      "FLAGGED                64.821429                95.0\n",
      "PENDING                28.570000                 0.0\n",
      "REJECTED                7.604167                31.0\n",
      "SUBMITTED                    NaN                 0.0\n"
     ]
    }
   ],
   "source": [
    "# For SQL Query:\n",
    "print(receipts_df.groupby('rewardsReceiptStatus').agg({'totalSpent': 'mean', 'purchasedItemCount': 'sum'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0ae45-269c-4235-8075-7c6ef92b0179",
   "metadata": {},
   "source": [
    "Assuming Finished is accepted: Accepted is greater"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
